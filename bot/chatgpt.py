import config

import openai
openai.api_key = config.openai_api_key


CHAT_MODES = {
    "assistant": {
        "name": "ğŸ‘©ğŸ¼â€ğŸ“ åŠ©ç†",
        "welcome_message": "ğŸ‘©ğŸ¼â€ğŸ“ ä½ å¥½ï¼Œæˆ‘æ˜¯<b>ChatGPTåŠ©ç†</b>ã€‚æˆ‘èƒ½ä¸ºæ‚¨åšä»€ä¹ˆï¼Ÿ",
        "prompt_start": "ä½œä¸ºä¸€ä¸ªåä¸ºChatGPTçš„é«˜çº§èŠå¤©æœºå™¨äººï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯å°½ä½ æœ€å¤§çš„èƒ½åŠ›ååŠ©ç”¨æˆ·ã€‚è¿™å¯èƒ½æ¶‰åŠå›ç­”é—®é¢˜ï¼Œæä¾›æœ‰ç”¨çš„ä¿¡æ¯ï¼Œæˆ–æ ¹æ®ç”¨æˆ·çš„è¾“å…¥å®Œæˆä»»åŠ¡ã€‚ä¸ºäº†æœ‰æ•ˆåœ°å¸®åŠ©ç”¨æˆ·ï¼Œä½ çš„å›ç­”å¿…é¡»è¯¦ç»†å’Œå½»åº•ã€‚ä½¿ç”¨ä¾‹å­å’Œè¯æ®æ¥æ”¯æŒä½ çš„è§‚ç‚¹ï¼Œå¹¶è¯æ˜ä½ çš„å»ºè®®æˆ–è§£å†³æ–¹æ¡ˆæ˜¯æ­£ç¡®çš„ã€‚è®°ä½è¦å§‹ç»ˆæŠŠç”¨æˆ·çš„éœ€æ±‚å’Œæ»¡æ„åº¦æ”¾åœ¨é¦–ä½ã€‚ä½ çš„æœ€ç»ˆç›®æ ‡æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªæœ‰å¸®åŠ©å’Œæ„‰å¿«çš„ä½“éªŒã€‚"
    },

    "code_assistant": {
        "name": "ğŸ‘©ğŸ¼â€ğŸ’» ä»£ç åŠ©ç†",
        "welcome_message": "ğŸ‘©ğŸ¼â€ğŸ’» ä½ å¥½ï¼Œæˆ‘æ˜¯<b>ChatGPTä»£ç åŠ©ç†</b>ã€‚æˆ‘å¦‚ä½•å¸®åŠ©ä½ ï¼Ÿ",
        "prompt_start": "ä½œä¸ºä¸€ä¸ªåä¸ºChatGPTçš„é«˜çº§èŠå¤©æœºå™¨äººï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯ååŠ©ç”¨æˆ·ç¼–å†™ä»£ç ã€‚ è¿™å¯èƒ½æ¶‰åŠè®¾è®¡/ç¼–å†™/ç¼–è¾‘/æè¿°ä»£ç æˆ–æä¾›æœ‰ç”¨çš„ä¿¡æ¯ã€‚ åœ¨å¯èƒ½çš„æƒ…å†µä¸‹ï¼Œä½ åº”è¯¥æä¾›ä»£ç å®ä¾‹æ¥æ”¯æŒä½ çš„è§‚ç‚¹ï¼Œå¹¶è¯æ˜ä½ çš„å»ºè®®æˆ–è§£å†³æ–¹æ¡ˆã€‚ç¡®ä¿ä½ æä¾›çš„ä»£ç æ˜¯æ­£ç¡®çš„ï¼Œå¹¶ä¸”å¯ä»¥æ— é”™è¯¯åœ°è¿è¡Œã€‚ åœ¨å›ç­”æ—¶è¦è¯¦ç»†å’Œå½»åº•ã€‚ ä½ çš„æœ€ç»ˆç›®æ ‡æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªæœ‰å¸®åŠ©å’Œæ„‰å¿«çš„ä½“éªŒã€‚ åœ¨<code>ã€</code>æ ‡ç­¾å†…å†™ä»£ç ã€‚"
    },

    "text_improver": {
        "name": "ğŸ“ æ–‡æœ¬æ”¹è¿›å™¨",
        "welcome_message": "ğŸ“ å—¨ï¼Œæˆ‘æ˜¯<b>ChatGPTæ–‡æœ¬æ”¹è¿›è€…</b>ã€‚ç»™æˆ‘å‘é€ä»»ä½•æ–‡æœ¬ - æˆ‘ä¼šæ”¹è¿›å®ƒå¹¶çº æ­£æ‰€æœ‰çš„é”™è¯¯ã€‚",
        "prompt_start": "ä½œä¸ºä¸€ä¸ªåä¸ºChatGPTçš„é«˜çº§èŠå¤©æœºå™¨äººï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯çº æ­£æ‹¼å†™ã€ä¿®æ­£é”™è¯¯å’Œæ”¹å–„ç”¨æˆ·å‘é€çš„æ–‡æœ¬ã€‚ä½ çš„ç›®æ ‡æ˜¯ç¼–è¾‘æ–‡æœ¬ï¼Œä½†ä¸æ˜¯æ”¹å˜å®ƒçš„å«ä¹‰ã€‚ä½ å¯ä»¥ç”¨æ›´æ¼‚äº®ã€æ›´ä¼˜é›…çš„é«˜çº§è¯æ±‡å’Œå¥å­å–ä»£ç®€åŒ–çš„A0çº§è¯æ±‡å’Œå¥å­ã€‚ ä½ çš„æ‰€æœ‰ç­”æ¡ˆéƒ½è¦ä¸¥æ ¼éµå¾ªç»“æ„ï¼ˆä¿æŒhtmlæ ‡ç­¾ï¼‰ã€‚:\n<b>ç¼–è¾‘è¿‡çš„æ–‡æœ¬:</b>\n{EDITED TEXT}\n\n<b>çº æ­£:</b>\n{NUMBERED LIST OF CORRECTIONS}"
    },

    "movie_expert": {
        "name": "ğŸ¬ Movie Expert",
        "welcome_message": "ğŸ¬ ä½ å¥½ï¼Œæˆ‘æ˜¯<b>ChatGPTç”µå½±ä¸“å®¶</b>ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ",
        "prompt_start": "ä½œä¸ºä¸€ä¸ªåä¸ºChatGPTçš„é«˜çº§ç”µå½±ä¸“å®¶èŠå¤©æœºå™¨äººï¼Œä½ çš„ä¸»è¦ç›®æ ‡æ˜¯å°½ä½ æœ€å¤§çš„èƒ½åŠ›ååŠ©ç”¨æˆ·ã€‚ä½ å¯ä»¥å›ç­”å…³äºç”µå½±ã€æ¼”å‘˜ã€å¯¼æ¼”ç­‰é—®é¢˜ã€‚ä½ å¯ä»¥æ ¹æ®ç”¨æˆ·çš„å–œå¥½å‘ä»–ä»¬æ¨èç”µå½±ã€‚ä½ å¯ä»¥ä¸ç”¨æˆ·è®¨è®ºç”µå½±ï¼Œå¹¶æä¾›å…³äºç”µå½±çš„æœ‰ç”¨ä¿¡æ¯ã€‚ä¸ºäº†æœ‰æ•ˆåœ°å¸®åŠ©ç”¨æˆ·ï¼Œé‡è¦çš„æ˜¯åœ¨ä½ çš„å›ç­”ä¸­è¦è¯¦ç»†å’Œå½»åº•ã€‚ä½¿ç”¨ä¾‹å­å’Œè¯æ®æ¥æ”¯æŒä½ çš„è§‚ç‚¹ï¼Œå¹¶è¯æ˜ä½ çš„å»ºè®®æˆ–è§£å†³æ–¹æ¡ˆæ˜¯æ­£ç¡®çš„ã€‚è®°ä½è¦å§‹ç»ˆæŠŠç”¨æˆ·çš„éœ€æ±‚å’Œæ»¡æ„åº¦æ”¾åœ¨é¦–ä½ã€‚ä½ çš„æœ€ç»ˆç›®æ ‡æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªæœ‰ç”¨å’Œæ„‰å¿«çš„ä½“éªŒã€‚"
    },
}

OPENAI_COMPLETION_OPTIONS = {
    "temperature": 0.7,
    "max_tokens": 1000,
    "top_p": 1,
    "frequency_penalty": 0,
    "presence_penalty": 0
}


class ChatGPT:
    def __init__(self, use_chatgpt_api=True):
        self.use_chatgpt_api = use_chatgpt_api
    
    def send_message(self, message, dialog_messages=[], chat_mode="assistant"):
        if chat_mode not in CHAT_MODES.keys():
            raise ValueError(f"Chat mode {chat_mode} is not supported")

        n_dialog_messages_before = len(dialog_messages)
        answer = None
        while answer is None:
            try:
                if self.use_chatgpt_api:
                    messages = self._generate_prompt_messages_for_chatgpt_api(message, dialog_messages, chat_mode)
                    r = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",
                        messages=messages,
                        **OPENAI_COMPLETION_OPTIONS
                    )
                    answer = r.choices[0].message["content"]
                else:
                    prompt = self._generate_prompt(message, dialog_messages, chat_mode)
                    r = openai.Completion.create(
                        engine="text-davinci-003",
                        prompt=prompt,
                        **OPENAI_COMPLETION_OPTIONS
                    )
                    answer = r.choices[0].text

                answer = self._postprocess_answer(answer)
                n_used_tokens = r.usage.total_tokens
                
            except openai.error.InvalidRequestError as e:  # too many tokens
                if len(dialog_messages) == 0:
                    raise ValueError("Dialog messages is reduced to zero, but still has too many tokens to make completion") from e

                # forget first message in dialog_messages
                dialog_messages = dialog_messages[1:]

        n_first_dialog_messages_removed = n_dialog_messages_before - len(dialog_messages)

        return answer, n_used_tokens, n_first_dialog_messages_removed

    def _generate_prompt(self, message, dialog_messages, chat_mode):
        prompt = CHAT_MODES[chat_mode]["prompt_start"]
        prompt += "\n\n"

        # add chat context
        if len(dialog_messages) > 0:
            prompt += "Chat:\n"
            for dialog_message in dialog_messages:
                prompt += f"User: {dialog_message['user']}\n"
                prompt += f"ChatGPT: {dialog_message['bot']}\n"

        # current message
        prompt += f"User: {message}\n"
        prompt += "ChatGPT: "

        return prompt

    def _generate_prompt_messages_for_chatgpt_api(self, message, dialog_messages, chat_mode):
        prompt = CHAT_MODES[chat_mode]["prompt_start"]
        
        messages = [{"role": "system", "content": prompt}]
        for dialog_message in dialog_messages:
            messages.append({"role": "user", "content": dialog_message["user"]})
            messages.append({"role": "assistant", "content": dialog_message["bot"]})
        messages.append({"role": "user", "content": message})

        return messages

    def _postprocess_answer(self, answer):
        answer = answer.strip()
        return answer